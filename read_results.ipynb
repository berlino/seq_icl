{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name_to_exp = {\n",
    "    \"h3\": \"dfa/h3\",\n",
    "    \"linear_transformer\": \"dfa/linear_transformer\",\n",
    "    \"hyena\": \"dfa/hyena\",\n",
    "    \"transformer\": \"dfa/transformer\",\n",
    "    \"rwkv\": \"dfa/rwkv\",\n",
    "    \"s4d\": \"dfa/s4d\",\n",
    "    \"lstm\": \"dfa/lstm\",\n",
    "    \"retention\": \"dfa/retnet\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glob all checkpoints\n",
    "run_folders = glob.glob(\"experiments/**/wandb/run-*/\", recursive=True)\n",
    "# create a map\n",
    "name_to_folder = {}\n",
    "for folder in run_folders:\n",
    "    folder = folder.replace(\"//\", \"/\").strip('/')\n",
    "    subpaths = folder.split('/')\n",
    "    name = subpaths[-1]\n",
    "    name = name.split(\"-\")[-1]\n",
    "    main_folder = \"/\".join((subpaths[:-2]))\n",
    "    folder = os.path.join(main_folder, \"checkpoints\", \"val\", \"loss.ckpt\")\n",
    "    name_to_folder[name] = folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "entity, project = \"akyurek\", \"associative_recall_learning_curves_eval\"\n",
    "runs = api.runs(entity + \"/\" + project)\n",
    "\n",
    "summary_list, config_list, name_list, attr_list = [], [], [], []\n",
    "for run in runs:\n",
    "    # .summary contains output keys/values for\n",
    "    # metrics such as accuracy.\n",
    "    #  We call ._json_dict to omit large files\n",
    "    summary_list.append(run.summary._json_dict)\n",
    "\n",
    "    # .config contains the hyperparameters.\n",
    "    #  We remove special values that start with _.\n",
    "    config_list.append({k: v for k, v in run.config.items()})\n",
    "\n",
    "    # .name is the human-readable name of the run.\n",
    "    name_list.append(run.name)\n",
    "\n",
    "    #\n",
    "    attr_list.append(run._attrs)\n",
    "\n",
    "\n",
    "runs_df = pd.DataFrame(\n",
    "    {\n",
    "        \"summary\": summary_list,\n",
    "        \"config\": config_list,\n",
    "        \"name\": name_list,\n",
    "        \"attr\": attr_list,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ckpt(x):\n",
    "    ckpt = x.config[\"train\"]\n",
    "    ckpt = ckpt[\"ckpt\"]\n",
    "    if ckpt is None:\n",
    "        folder = name_to_folder.get(x.attr[\"name\"], None)\n",
    "        if folder:\n",
    "            ckpt = os.path.join(\n",
    "                \"/raid/lingo/akyurek/git/iclmodels/\",\n",
    "                folder,\n",
    "                # \"checkpoints\",\n",
    "                # \"val\",\n",
    "                # \"loss.ckpt\",\n",
    "            )\n",
    "\n",
    "    return ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nested_arg(x, args):\n",
    "    for arg in args:\n",
    "        try:\n",
    "            x = x[arg]\n",
    "        except:\n",
    "            return None\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in [\"dfa_accuracy\", \"model_dfa_diff\", \"loss\", \"accuracy_ignore_index\"]:\n",
    "    runs_df[f\"final_test/{metric}\"] = runs_df.summary.map(\n",
    "        lambda x: x.get(f\"final_test/{metric}\", None)\n",
    "    )\n",
    "for config in [\n",
    "    \"model.layer._name_\",\n",
    "    \"dataset.num_examples\",\n",
    "    \"model.n_layer\",\n",
    "    \"model.d_model\",\n",
    "    \"optimizer.lr\",\n",
    "    \"optimizer.weight_decay\",\n",
    "    \"experiment\",\n",
    "    \"hydra.run.dir\",\n",
    "    \"model.attn_cfg.n_heads\",\n",
    "    \"model.attn_cfg.num_heads\",\n",
    "    \"dataset.vocab_size\",\n",
    "    \"dataset.input_seq_len\",\n",
    "    \"dataset.batch_size\",\n",
    "    \"model.attn_layer_idx\",\n",
    "]:\n",
    "    config_parts = config.split(\".\")\n",
    "    # get the value by nested index\n",
    "    runs_df[config] = runs_df.config.map(lambda x: get_nested_arg(x, config_parts))\n",
    "\n",
    "# if model.layer._name_ is None, set it to linear attention\n",
    "runs_df[\"model.layer._name_\"] = runs_df[\"model.layer._name_\"].fillna(\"linear_transformer\")\n",
    "\n",
    "runs_df[\"ckpt\"] = runs_df.apply(get_ckpt, axis=1)\n",
    "\n",
    "\n",
    "# runs_df.dropna(subset=[\"final_test/model_dfa_diff\"], inplace=True)\n",
    "runs_df.sort_values(by=\"final_test/loss\", ascending=True, inplace=True)\n",
    "\n",
    "# remove columns\n",
    "runs_df.drop(columns=[\"summary\", \"config\", \"attr\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make neurips conference quality plots\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('/raid/lingo/akyurek/mplstyle')\n",
    "plt.rc('font', serif='Times')\n",
    "plt.rc('text', usetex=False)\n",
    "plt.rcParams['figure.dpi'] = 250\n",
    "plt.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = {\n",
    "    \"transformer\": \"Transformer\",\n",
    "    \"transformer_2\": \"Transformer (2 layers)\",\n",
    "    \"transformer_1\": \"Transformer (1 layers)\",\n",
    "    \"lstm\": \"LSTM\",\n",
    "    \"hyena\": \"Hyena\",\n",
    "    \"h3\": \"H3\",\n",
    "    \"s4d\": \"S4D\",\n",
    "    \"linear_transformer\": \"Linear Transformer\",\n",
    "    \"rwkv\": \"RWKV\",\n",
    "    \"retention\": \"RetNet\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig size\n",
    "plt.rcParams.update({\"figure.figsize\": (6, 4)})\n",
    "data = runs_df.loc[\n",
    "    runs_df.groupby([\"model.layer._name_\", \"dataset.num_examples\"])[\n",
    "        \"final_test/accuracy_ignore_index\"\n",
    "    ].idxmax()\n",
    "]\n",
    "data = data.replace({\"model.layer._name_\": model_names})\n",
    "# display(data)\n",
    "ax = sns.lineplot(\n",
    "    data=data,\n",
    "    x=\"dataset.num_examples\",\n",
    "    y=\"final_test/accuracy_ignore_index\",\n",
    "    hue=\"model.layer._name_\",\n",
    "    marker=\"o\",\n",
    "    hue_order=[\"Transformer\", \"LSTM\", \"Hyena\", \"H3\", \"S4D\", \"Linear Transformer\", \"RWKV\", \"RetNet\"],\n",
    ")\n",
    "ax.set_xlabel(\"# Training Examples\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set(xscale=\"log\")\n",
    "ax.set_xticks([150, 300, 625, 1250, 2500, 5000])\n",
    "ax.legend(title='Model')\n",
    "ax.get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_to_run = []\n",
    "\n",
    "data.sort_values(by=\"dataset.num_examples\", ascending=False, inplace=True)\n",
    "for i, row in data.iterrows():\n",
    "    model_type = row[\"model.layer._name_\"]\n",
    "    exp_name = layer_name_to_exp[model_type]\n",
    "\n",
    "    prefix = f\"export PYTHONHASHSEED=0; export CUDA_VISIBLE_DEVICES={i % 16}; python eval.py wandb.project=dfa_best_runs hydra.run.dir='experiments/hiddens_{row['dataset.num_examples']}/{model_type}/' \"\n",
    "    prefix += f\"experiment={exp_name} train.test=True dataset.num_test_examples=1000 train.ckpt='{row['ckpt']}' \"\n",
    "\n",
    "    for k in [\"dataset.num_examples\", \"model.n_layer\", \"model.d_model\", \"optimizer.lr\", \"optimizer.weight_decay\"]:\n",
    "        prefix += f\"{k}={row[k]} \"\n",
    "\n",
    "    if not math.isnan(row[\"model.attn_cfg.n_heads\"]):\n",
    "        prefix += f\"model.attn_cfg.n_heads={int(row['model.attn_cfg.n_heads'])} \"\n",
    "        if model_type != \"retention\":\n",
    "            prefix += \"+model.return_attention=True \"\n",
    "    if not math.isnan(row[\"model.attn_cfg.num_heads\"]):\n",
    "        prefix += f\"model.attn_cfg.num_heads={int(row['model.attn_cfg.num_heads'])} \"\n",
    "        if model_type != \"retention\":\n",
    "            prefix += \"+model.return_attention=True \"\n",
    "\n",
    "    if row[\"model.attn_layer_idx\"]:\n",
    "        prefix += f\"model.attn_layer_idx='{list(row['model.attn_layer_idx'].values())}' \"\n",
    "\n",
    "    prefix += f\"> experiments/hiddens_{row['dataset.num_examples']}/logs/{i}  2>&1 &\"\n",
    "    prefix = prefix.strip()\n",
    "\n",
    "    runs_to_run.append(prefix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\".join(runs_to_run))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig size\n",
    "plt.rcParams.update({\"figure.figsize\": (6, 4)})\n",
    "data = runs_df.loc[\n",
    "    runs_df.groupby([\"model.layer._name_\", \"dataset.num_examples\"])[\n",
    "        \"final_test/model_dfa_diff\"\n",
    "    ].idxmin()\n",
    "]\n",
    "ax = sns.lineplot(\n",
    "    data=data,\n",
    "    x=\"dataset.num_examples\",\n",
    "    y=\"final_test/model_dfa_diff\",\n",
    "    hue=\"model.layer._name_\",\n",
    "    marker=\"o\",\n",
    ")\n",
    "# update x label\n",
    "ax.set_xlabel(\"# Training Examples\")\n",
    "ax.set_ylabel(\"L1\")\n",
    "ax.set(xscale=\"log\")\n",
    "ax.set_xticks([1000, 2500, 5000, 10000, 20000, 40000])\n",
    "ax.get_xaxis().set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "ax.legend(title='Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iclmodels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
